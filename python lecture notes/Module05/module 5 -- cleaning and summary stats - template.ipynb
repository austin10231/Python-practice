{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the outputs in a cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data of the survey taken by Data Science students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv('data science survey.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't like this data set for a variety of reasons:\n",
    "<ul>\n",
    "<li>Columnn headers are too long\n",
    "<li>Some cell values are too long\n",
    "<li>Some cell values are yes/no, but we prefer 1/0\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's change some of the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Timestamp',\n",
    "             'Job',\n",
    "             'BachTime',\n",
    "             'Program',\n",
    "             'ProgSkills',\n",
    "             'C',\n",
    "             'CPP',\n",
    "             'CS',\n",
    "             'Java',\n",
    "             'Python',\n",
    "             'JS',\n",
    "             'R',\n",
    "             'SQL',\n",
    "             'SAS',\n",
    "             'Excel',\n",
    "             'Tableau',\n",
    "             'Regression',\n",
    "             'Classification',\n",
    "             'Clustering']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print top 5 rows\n",
    "df.head(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the column names look a lot better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Let's remove timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we don't need the timestamps. Here is how to remove a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop column 'Timestamp' from df\n",
    "# If you set inplace = True , the drop() method will delete rows or columns directly from the original dataframe.\n",
    "df.???(columns='Timestamp',inplace=???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace job with 0 (no job), 0.5 (part time), and 1 (full time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We want to replace the values of the column \"Job\", as follows:</p>\n",
    "<p>\n",
    "<ul>\n",
    "<li><i>No, I'm not working at the moment</i> --> 0\n",
    "<li><i>Yes, I have a part-time job</i> --> 0.5\n",
    "<li><i>Yes, I have a full-time job</i> --> 1\n",
    "</ul>\n",
    "</p>\n",
    "<p>\n",
    "We will show three alternative solutions (1, 2, and 3) to perform this task. They will result in the creation of three columns (Job1, Job2, and Job3). At the end, we will delete the original column Job, we will delete two of these columns, and we will rename the remaining column \"Job\".\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 1 (column Job1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a column 'Job1' through <i>df.loc</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['Job'] == 'No, I\\'m not working at the moment').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a new column 'Job1' with 0 (no job), 0.5 (part time), and 1 (full time)\n",
    "df.???[df['Job'] == 'No, I\\'m not working at the moment', ???] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.???[df['Job'] == 'Yes, I have a part-time job', ???] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.???[df['Job'] == 'Yes, I have a full-time job', ???] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print column Job1's top 10 rows\n",
    "df.loc[:,'Job1'][:???]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print column Job1's top 10 rows\n",
    "df.Job1[:???]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or use **.unique()** and **.nunique()** to check the convertion results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print unique values in column Job1\n",
    "df.Job1.???()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of unique values in column Job1\n",
    "df.Job1.???()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will use the function <b>apply</b> on the column <i>Job</i>. The function \"apply\" requires as input a function that specifies how to transform each value. The function should perform the following transformations:\n",
    "<ul>\n",
    "<li>No, I'm not working at the moment => 0</li>\n",
    "<li>Yes, I have a part-time job => 0.5</li>\n",
    "<li>Yes, I have a full-time job => 1</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a function to replce job string with 0 (no job), 0.5 (part time), and 1 (full time)\n",
    "\n",
    "def Job2Num(Job_String):\n",
    "    if Job_String == 'No, I\\'m not working at the moment':\n",
    "        return ???\n",
    "    elif Job_String == 'Yes, I have a part-time job':\n",
    "        return ???\n",
    "    else:\n",
    "        return ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Job2Num function to generate a new column 'Job2' with 0 (no job), 0.5 (part time), and 1 (full time)\n",
    "\n",
    "df['Job2'] = df['Job'].???(Job2Num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print top 6 rows\n",
    "df.head(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another version of Job2Num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a function to replce job string with 0 (no job), 0.5 (part time), and 1 (full time)\n",
    "# using .startswith function for string comparison\n",
    "\n",
    "def Job2NumV2(Job_String):\n",
    "    if Job_String.???('No'):\n",
    "        return 0\n",
    "    elif 'part-time' in Job_String:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of declaring a function as above, we can pass a lambda (or anonymous) function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a lambda function to replce job string with 0 (no job), 0.5 (part time), and 1 (full time)\n",
    "df['Job3'] = df['Job'].apply(??? x: 0 if x.startswith('No') \\\n",
    "                            else 0.5 if 'part-time' in x \\\n",
    "                            else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print top 10 rows\n",
    "df.head(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame has now the original column <i>Job</i> and three identical columns <i>Job1</i>, <i>Job2</i>, and <i>Job3</i>. We delete the original column <i>Job</i>, as well as <i>Job1</i> and <i>Job2</i>, and then we will rename the remaining column from <i>Job3</i> to <i>Job</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns Job1, Job2, and Job3.\n",
    "df.???(columns=[???], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the column Job3 to Job.\n",
    "df.???(columns={'Job3':'Job'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace <i>BachTime</i> with a dummy variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time from graduation <i>BachTime</i> can have the following values:\n",
    "<ul>\n",
    "<li>less than 1 year ago</li>\n",
    "<li>longer than 1 year ago but less than 3 years ago</li>\n",
    "<li>longer than 3 years ago but less than 5 years ago</li>\n",
    "<li>over 5 years ago</li>\n",
    "</ul>\n",
    "\n",
    "We want to conver the column BachTime to <i>dummy variables</i>, that is we want to create four columns ('Bach_0to1', 'Bach_1to3', 'Bach_3to5', 'Bach_5Plus') of which only one will be 1 and the others 0. These columns will indicate which is the duration of the time from the bachelor's degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method <i>get_dummies</i> performs precisely this task. It transforms a column that contains $V$ unique values into $V$ new column (one for each value $v \\in V$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create two dummy dataframes to try out two different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use get_dummies to convert categorical variable into dummy/indicator variables.\n",
    "dumDF = pd.???(df, columns=['BachTime'])\n",
    "dumDF1 = pd.???(df, columns=['BachTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumDF is dumDF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dumDF1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names generated by the method <i>get_dummies</i> are very wordy because they use the original cell contents. So, let us rename the columns. We can use two different methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If want to see all columns, can use pd.set_option cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### option 1:\n",
    "<b>We are using dumDF1</b>\n",
    "\n",
    "We can do it column by column with rename():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumDF1.???(columns={'BachTime_< 1 year ago':'Bach_0to1'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use axis=1 option\n",
    "# dumDF1.rename({'BachTime_< 1 year ago':'Bach_0to1'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumDF1.???(columns={'BachTime_longer than 1 year ago but less than 3 years ago':'Bach_1to3'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumDF1.???(columns={'BachTime_longer than 3 years ago but less than 5 years ago':'Bach_3to5'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumDF1.???(columns={'BachTime_over 5 years ago':'Bach_5Plus'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumDF1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Or, we do the following:\n",
    "\n",
    "<b>We are using dumDF</b>\n",
    "1. transform the columns into a list\n",
    "2. modify the list\n",
    "3. set the new columns vector all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column index of dumDF and convert them to list (tolist())\n",
    "newcolNames = dumDF.columns.???()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the last four elements in newcolNames list\n",
    "newcolNames[???:] = ['Bach_0to1', 'Bach_1to3', 'Bach_3to5', 'Bach_5Plus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the columns index with newcolNames\n",
    "dumDF.columns = newcolNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumDF.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overwrite our original dataframe df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dumDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace Yes with 1 and No with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us replace everywhere \"Yes\" with 1 and \"No\" with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The replace() function is used to replace values given in to_replace with value.\n",
    "df.replace(to_replace=???, value=???, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(to_replace=???, value=???, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding simple columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a column that counts how many programming languages students know. Languages = C+CPP+CS+Java+Python+JS+R+SQL+SAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Languages'] = df.C+df.CPP+df.CS+df.Java+df.Python+df.JS\\\n",
    "                    +df.R+df.SQL+df.SAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To rearrange column order:<br/>\n",
    "<b>reindex(columns=[the columns in the order that you want])</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns\n",
    "df.???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's place <i>Languages</i> first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the df's column label index and convert them to a list\n",
    "list_of_columns = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop the last element out and insert it back to list_of_columns at position 0\n",
    "list_of_columns.insert(0, list_of_columns.pop(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check top 3 elements in list_of_columns\n",
    "list_of_columns[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use reindex function to reorder columns \n",
    "df = df.???(columns=list_of_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding complex columns (advanced topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a 0-1 column called \"Expert\" if <i>Languages</i> is 3 or more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, note that you can do it very easily with what you already know:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Languages']>=3,???]=???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Languages']<3,???]=???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Languages'] >= 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True/False operate with a floating point (+ 0.0) will convert to 1 or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covert boolean into 0/1\n",
    "(df['Languages'] >= 3) + ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column 'Expert1' using above-mentioned technique\n",
    "df['Expert1'] = (df['Languages'] >= 3) + ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check top10 rows in Expert1 column\n",
    "df['Expert1'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But suppose that the calculation is complicated. First, we need to define a function that given a row (i.e., a Series that represents a student) returns 1 if the student is and expert (and 0 otherwise). This row has index labels 'Job', 'BachTime, 'Program', etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExpertFunction(row):\n",
    "    ??? row['Languages'] >= 3:\n",
    "        return 1.0\n",
    "    ???:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we use the function <b>apply</b> with axis=1, which applies the function across columns and returns a Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function row-wise\n",
    "df['Expert2']=df.apply(ExpertFunction, axis=???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, instead of defining a function with <i>def</i>, we can use a lambda function, which allows us to define the function \"inline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Expert3'] = df.apply(??? row: 1.0 if row['Languages'] >= 3 else 0.0, axis=???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 'Expert3','Expert2',and'Expert1' column\n",
    "df.???(['Expert3','Expert2','Expert1'],axis=???, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Warning</b>: <i>DataFrame.apply</i> is slow, especially when called on all rows (i.e., axis=1). If you can, you should use operations among Series and scalars. The performance on the example above can be improved a lot as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit df['Expert'] = df.apply(lambda row : 1.0 if row['Languages'] >= 3 else 0.0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit df['Expert'] = df.Languages.apply(lambda x: 1.0 if x>=3 else 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame.apply vs Series.apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pandas 0.20, DataFrame.apply is slow whereas Series.apply is fast. For example, say that we want to add a column <i>ProgramLower</i> with the lower case value of Program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 1: DataFrame.apply (slow! Do not use!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit df.apply(lambda x: x['Program'].lower(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 2: Series.apply (fast because it uses vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit df.Program.apply(lambda y: y.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write it to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the cleaned dataframe as a new csv file\n",
    "df.???('cleaned_survey.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas provides many simple \"summary functions\" which restructure the data in some useful way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.???()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method generates a high-level summary of the attributes of the given column. It is type-aware, meaning that its output changes based on the dtype of the input. The output above only makes sense for numerical data; for string data here's what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply describe function to program series\n",
    "df.???.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see a list of unique values we can use the **unique** function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use unique() function to check unique values in Program column\n",
    "df.Program.???()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of unique values in Program column\n",
    "???(df.Program.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see a list of unique values and how often they occur in the dataset, we can use the **value_counts** method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use value_counts function to count unique values in Program column\n",
    "df.Program.???()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "versus .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The count() method counts the number of not empty values for each row\n",
    "df.Program.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.shape** Return a tuple representing the dimensionality of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many students know SQL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SQL.???()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the average programming skills of MSIS students? Compare it to that of MBA students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[???].ProgSkills.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[???].ProgSkills.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many students know classification better than clustering? And how many clustering better than classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(???).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(???).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the strongest correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What are the top 10 correlations and the top 10 anti-correlations? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer this question, we need to \"stack\" the result of <i>cor.stack()</i>, which means turning it into a Series with a \"Hierarchical index\" (that is, an index of two elements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = df.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply stack function\n",
    "cor.???()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the correlations equal to 1 (they are self correlations); then, pick one correlation every two (as they all appear twice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use list slicing: x[startAt:endBefore:skip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor[cor < 1].stack().nlargest(???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation betweem Classification and Clustering is the same as correlation betweem Clustering and Classification\n",
    "# Remove the duplicated correlations\n",
    "cor[cor < 1].stack().nlargest(???)[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for negative correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor[cor < 1].stack().???(20)[::2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
